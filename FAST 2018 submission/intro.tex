% Transactions in big-data platforms
In recent years, transaction processing~\cite{Gray:1992:TPC:573304} technologies have paved their way into many-petabyte big data 
platforms~\cite{Percolator2010,Spanner2012,Omid2017}. 
%In some cases, they are built into the storage system itself~\cite{Spanner2012} whereas in the others they are standalone services~\cite{Omid2017}. 
Modern industrial transaction processing systems~\cite{Percolator2010,Omid2017,tephra,cockroach} complement 
existing underlying key-value storage with {\em atomicity}, {\em consistency}, {\em isolation\/} and 
{\em durability} (ACID) semantics that enable programmers to perform 
complex data manipulation without over-complicating their applications. 
For instance, Google's Percolator~\cite{Percolator2010} runs ACID transactions atop BigTable, 
Apache's Phoenix, Tephra, and Omid support transactions over Apache HBase~\cite{hbase}, and CockroachDB~\cite{cockroach} is based on RocksDB. 
%This allows for  reuse, and affords them the flexibility to continue to offer capabilities from the NoSQL world alongside new functionalities. 

Transaction support in web-scale applications started from specific use cases like real-time content indexing~\cite{Percolator2010,
Omid2017} but has since expanded to full-scale SQL-compliant OLTP and operational analytics~\cite{Phoenix, F1-2013}.


Similarly to many technologies, the adoption of transactions took a  ``functionality-first" trajectory. 
For example, the developers of Google Spanner~\cite{Spanner2012} wrote: ``We believe it
is better to have application programmers deal with performance problems due to overuse 
of transactions as bottlenecks arise, rather than always coding around the lack of transactions''. 
Yet the expectation for high performance is rapidly picking up. 
Whereas early transaction systems were not latency-sensitive~\cite{Percolator2010, Omid2017}, 
with the thrust into new interactive domains like messaging~\cite{Borthakur:2011} and algorithmic 
trading~\cite{opentsdb}, latency becomes essential.  For example,  SLAs for interactive user experience
mandate that simple updates and point queries  complete within single-digit milliseconds, 
This paper is motivated by such  applications.

\remove{ % Idit: removed the following two paragraphs for blind review; moved some content above and below
Consider, for example, the platform powering Yahoo! Mail, which serves hundreds of millions of users. 
The Mail backend ingests billions of messages daily; messages undergo both machine 
classification (e.g., for spam filtering, thread detection, and ``smart views''~\cite{smart-view}),
%\footnote{\footnotesize{\url{https://yahoohelpcommunity.tumblr.com/post/118485031125/getting-to-know-smart-views-in-yahoo-mail}}}
and user manipulation (e.g., starring, tagging, and moving between folders).    
Mail users browse their mail and search for content, issuing many billions of requests a day; they
expect a consistent experience -- e.g., messages  do not 
disappear when moved between folders, starred content gets prioritized in search, folder counters are reliable, etc.

The Yahoo! Mail metadata platform is built on top of Apache HBase~\cite{hbase}, 
which provides reliable and scalable key-value storage. The system's first generation
was built without transaction support. This exposed  developers to very complex programming scenarios 
to achieve ACID behavior (e.g., consistent folder listings, atomic updates of multiple counters). 
%We would like to build the next generation of the system using a transaction API on top of HBase.
We have looked into building the next generation using  Omid~\cite{omid}, 
an Apache Incubator project which provides a transaction API on top of HBase, and 
is already in use at large scale at Yahoo~\cite{Omid2017}.
Unfortunately, while this makes programming much easier, it also jeopardizes 
the real-time latency SLA for interactive user experience. For example,  
simple updates and point queries must complete within single-digit milliseconds.
whereas Omid, which was designed for throughput-oriented data pipelines~\cite{Omid2017}, 
can induce latencies of tens to hundreds of milliseconds under high loads. 

Motivated by this example, 
}%remove

% Drum roll 
We present {\sys\/}~-- a low-latency {\em and\/} high-throughput transaction processing system for HBase. 
Similarly to other modern transaction managers~\cite{Percolator2010,Spanner2012,Omid2017,tephra,cockroach},
{\sys\/} provides a (somewhat relaxed) variant of \emph{snapshot isolation (SI)}~\cite{DBLP:conf/sigmod/BerensonBGMOO95},
which scales better than traditional serializability implementations. 
{\sys\/} is based on Apache Incubator Omid~\cite{omid}, but dissipates the principal bottleneck present therein.
%in the prior implementations the overhead of begin and commit operations. 
Its advantage is maximized for short  transactions, which are prevalent in latency-sensitive applications.
\sys\ processes  such transactions in a handful of milliseconds, whereas Omid, 
which was designed for throughput-oriented data pipelines~\cite{Omid2017}, 
can induce latencies of tens to hundreds of milliseconds under high loads. 
\sys\ also doubles the system throughput.
%Moreover, it is amenable to a simpler high availability solution than the original design. 
%, which is \inred{an order of magnitude higher than} previously achievable limits. 
%Different aspects of our protocol are inspired by other systems, while their combination is novel.
%, to the best of our knowledge. 

The performance improvement  is achieved by two design changes.
  First, we distribute persistent writes of transaction commit records, which is a centralized bottleneck in Omid. 
Second, we introduce a novel \emph{fast path} algorithm for short single-key transactions, which 
executes short transactions without the begin/commit overhead, 
 almost as fast as native HBase operations. This entails minor extensions to the underlying 
data store. The fast path is orthogonal to other protocol aspects, and can be supported in other 
transaction processing services. 
%, to enable local commits directly within the storage layer and verify the correctness of general 
%transactions in presence of such commits. 

We have implemented {\sys\/} %\footnote{\url{https://github.com/yonigottesman/incubator-omid/tree/localTransactions}} 
based on the open source Omid code\footnote{\url{https://omid.incubator.apache.org}}, 
and extended the HBase code to enable fast path 
transactions. %\footnote{\url{https://github.com/yonigottesman/hbase_local_transactions/tree/0.98-add-rmw}}. 
Our code is publicly available on github\footnote{Omitted for blind review.}. 
Our experiments on mid-range hardware show substantial performance improvements.
Under low load,
even without the fast path, \sys\ transactions are 4x to 5x faster than Omid's, 
and the fast path further reduces the latency of short transactions by another $55\%$ on average.
As system load increases, Omid's latency surges (at  $\sim\!\!\!150$K tps in our tests),  
whereas \sys's remains stable until we generate a higher load ($\sim\!\!250$K tps)
%, and increases four-fold at 500K tps.  
Fast path transactions incur no scalability
bottlenecks, and continue to execute at the low latency of native HBase operations regardless of system load
(thanks to HBase's near perfect horizontal scalability).
This comes at the cost of a minor (less than 15\%) negative impact on longer transactions. 
%{\inred{The system scales beyond 1M transactions per second on medium-end hardware,
%which surpasses Omid at least 4x.}} 
Additionally, \sys\ has negligible impact on  transaction abort rates.

% \Idit{The roadmap below is not essential; maybe replace with summary of contributions.}
The remainder of this paper is organized as follows:
In Section~\ref{sec:api} we define the  API and semantics of a transaction processing service. 
Section~\ref{sec:ll} presents \sys, without the fast path, and 
%Section~\ref{sec:ha} discusses its high availability mechanism. 
Section~\ref{sec:alg} then describes our support for fast path  transactions.  
Section~\ref{sec:eval} presents an empirical evaluation.
%In Section~\ref{sec:context} we generalize the fast path algorithm, and explain how it could be implemented in other systems. 
We review related work in Section ~\ref{sec:related} and conclude with Section~\ref{sec:conclusions}.
